# -*- coding: utf-8 -*-

"""
This software is part of GPU Ocean. 

Copyright (C) 2018  SINTEF Digital

This python class implements an ensemble of particles, each consisting
of a single drifter in its own ocean state. Each ocean model is 
perturbed during each timestep, using small scale perturbations.

This program is free software: you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.

This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.

You should have received a copy of the GNU General Public License
along with this program.  If not, see <http://www.gnu.org/licenses/>.
"""


from matplotlib import pyplot as plt
import matplotlib.gridspec as gridspec
import numpy as np
import time
import gc
import abc
import warnings 
import os, sys, datetime

import pycuda.driver as cuda

from gpuocean.SWEsimulators import CDKLM16
from gpuocean.utils import Common, ParticleInfo, Observation, SimReader
from gpuocean.ensembles import BaseOceanStateEnsemble
from gpuocean.dataassimilation import DataAssimilationUtils as dautils

try:
    from importlib import reload
except:
    pass


class EnsembleFromFiles(BaseOceanStateEnsemble.BaseOceanStateEnsemble):
    """
    Class that holds an ensemble of ocean states, which can be initialized
    from file, and where the true state can also be loaded from file.
    """

    
    def __init__(self, gpu_ctx, numParticles,
                 ensemble_directory,
                 true_state_directory,
                 observation_variance,
                 cont_write_netcdf=False,
                 use_lcg = False, xorwow_seed = None,
                 write_netcdf_directory = None,
                 observation_type = dautils.ObservationType.UnderlyingFlow,
                 randomize_initial_ensemble=False,
                 compensate_for_eta = True,
                 time0=None):
        """
        Initalizing ensemble from files.
        
        Arguments:
            gpu_ctx: CUDA context
            numParticles: Number of particles/ensemble members
            ensemble_directory: Directory in which NetCDF files defines the ensemble initial conditions.
                If the ensemble size is larger than the number of files with extension ".nc" in the given
                directory, initial states will be duplicated, and we assume that the model error ensures 
                that all particles are different soon enough.
            true_state_directory: Directory which should contain one and only one ".nc" file, which is expected 
                to describe the truth, and one and exactly one ".pickle" file, which should contain observations
                compatible with the Observation class.
            observation_variance: The R matrix. Acceptable forms are a scalar (assuming diagonal R), or 2x2 matrix 
                (assuming block diagonal R, each drifter independent).
            cont_write_netcdf: Flag to write the ensemble to netcdf files in a new directory.
            use_lcg: Flag for using LCG or curand as random number generators for the ensemble members' model errors
            write_netcdf_directory: The directory in which the NetCDF for each ensemble member should be written
            observation_type: Type of observation as dautils.ObservationType.UnderlyingFlow
            randomize_initial_ensemble: Whether the ensemble should be generated by random from the available
               initial conditions.
            compensate_for_eta: Whether or not the observations should be adjusted by the eta from the particle states.
        """
        
        #print('Welcome to the EnsembleFromFile')
        #print('Ensemble directory: ', ensemble_directory)
        #print('True state directory: ', true_state_directory)
        
        self.gpu_ctx = gpu_ctx
        self.gpu_stream = cuda.Stream()
        
        # Control that the ensemble and true state directories exist
        assert os.path.isdir(ensemble_directory), "Ensemble init folder does not exists: " + str(ensemble_directory)
        assert os.path.isdir(true_state_directory), "True state folder does not exists: " + str(true_state_directory)
        
        # List of files for NetCDF ensemble initialization, NetCDF truth, and pickle Observations  
        self.ensemble_init_nc_files = list(os.path.join(ensemble_directory, file) for file in os.listdir(ensemble_directory) if file.endswith('.nc'))
        self.true_state_nc_files = list(os.path.join(true_state_directory, file)  for file in os.listdir(true_state_directory) if file.endswith('.nc'))
        self.observation_files = list(os.path.join(true_state_directory, file)  for file in os.listdir(true_state_directory) if file.endswith('.pickle'))
        self.ensemble_init_nc_files.sort()
        
        assert len(self.ensemble_init_nc_files) > 0, "There should be at least one NetCDF file in ensemble directory " + str(ensemble_directory)
        assert len(self.true_state_nc_files) == 1, "There should only be one single NetCDF file in the true state directory " + str(true_state_directory)
        assert len(self.observation_files) == 1,   "There should only be one single pickle file in the true state directory " + str(true_state_directory)
        
        self.write_netcdf_directory = write_netcdf_directory
        if self.write_netcdf_directory is None:
            write_netcdf_folder_name = "ensemble_result_" + datetime.datetime.now().strftime("%Y_%m_%d-%H_%M_%S") + "/"
            self.write_netcdf_directory = os.path.join(os.getcwd(), write_netcdf_folder_name)
            #print("self.write_netcdf_directory: ", self.write_netcdf_directory)
        
        # Create the particle array
        self.numParticles = numParticles
        self.particles = [None]*(self.numParticles)
        
        # Create an array representing active particles
        # If one particle turns bad (e.g., becomes unstable), it is deactivated
        # and not used further in the ensemble.
        self.particlesActive = [True]*(self.numParticles)
        
        
        # Declare variables for true state and observations
        self.true_state_reader = None
        self.observations = None
        
        # Flag to writing ensemble simulation result to file:
        self.cont_write_netcdf = cont_write_netcdf
        self.use_lcg = use_lcg
        self.xorwow_seed = xorwow_seed
        
        # We will not simulate the true state, but read it from file:
        self.simulate_true_state = False
        
        self.observation_type = observation_type
        
        ### Then, call appropriate helper functions for initialization of ensemble and true states
        self._initializeEnsembleFromFile(randomize_initial_ensemble, time0)
        self._initializeTruthFromFile() 
        
        self.compensate_for_eta = compensate_for_eta
        
        ### Set some variables that are used by the super class:
        self.nx, self.ny = self.particles[0].nx, self.particles[0].ny
        self.dx, self.dy = self.particles[0].dx, self.particles[0].dy
        self.dt = self.particles[0].model_time_step
        self.t  = self.particles[0].t

        ### Initialize observations
        assert(np.isscalar(observation_variance) or observation_variance.shape == (2,2)), 'observation_variance must be scalar or 2x2 matrix'
        if np.isscalar(observation_variance):
            observation_cov = np.diag([observation_variance, observation_variance])
        self.observation_cov = observation_cov.astype(np.float32)
        self.observation_cov_inverse = np.linalg.inv(self.observation_cov).astype(np.float32)
        
        self._initializeObservationsFromFile() 
        self.driftersPerOceanModel = self.observations.get_num_drifters()
        
        
        # Store mean water_depth, and whether the equilibrium depth is constant across the domain
        H = self.particles[0].downloadBathymetry()[1][2:-2, 2:-2] # H in cell centers
        self.mean_depth = np.mean(H)
        self.constant_depth = np.max(H) == np.min(H)
        
        # ParticleInfo
        self._initializeParticleInfo()
        self._particleInfoFileDumpCounter = 0
        self._particleInfoExtraCells = None
        
        
    def _initializeEnsembleFromFile(self, randomize_initial_ensemble,time0):
        num_files = len(self.ensemble_init_nc_files)
        file_ids = np.arange(self.numParticles) % num_files
        if randomize_initial_ensemble:
            
            if self.numParticles < num_files:
                # Chose a random but unique set of initial conditions
                file_ids = np.random.choice(np.arange(num_files), 
                                            self.numParticles, replace=False)
            if self.numParticles > num_files:
                # Keep one ensemble member for each file, and sample the rest by random
                file_ids[num_files:] = np.random.choice(np.arange(num_files), 
                                                        self.numParticles-num_files, 
                                                        replace=True)
            
        
        for particle_id in range(self.numParticles):
            file_id = file_ids[particle_id]
            new_netcdf_filename = None
            if self.cont_write_netcdf:
                filename_only = "ensemble_member_" + str(particle_id).zfill(4) + ".nc"
                new_netcdf_filename = os.path.join(self.write_netcdf_directory, filename_only)
                
            if self.xorwow_seed is not None:
                xorwow_seed = self.xorwow_seed + particle_id
            else:
                xorwow_seed = None

            self.particles[particle_id] = CDKLM16.CDKLM16.fromfilename(self.gpu_ctx, 
                                                                       self.ensemble_init_nc_files[file_id],
                                                                       cont_write_netcdf=self.cont_write_netcdf,
                                                                       new_netcdf_filename=new_netcdf_filename,
                                                                       use_lcg=self.use_lcg, xorwow_seed=xorwow_seed,
                                                                       time0=time0)

    def _initializeParticleInfo(self):
        self.particleInfos = [None]*self.numParticles
        for p in range(self.numParticles):
            self.particleInfos[p] = ParticleInfo.ParticleInfo()
        
    
    def _initializeTruthFromFile(self):
        self.true_state_reader = SimReader.SimNetCDFReader(self.true_state_nc_files[0])

    def _initializeObservationsFromFile(self):    
        self.observations = Observation.Observation(observation_type=self.observation_type,
                                                    domain_size_x=self.getDomainSizeX(), 
                                                    domain_size_y=self.getDomainSizeY(),
                                                    nx=self.nx, ny=self.ny,
                                                    observation_variance=self.observation_cov[0,0])
        self.observations.read_pickle(self.observation_files[0])

    
        

    def cleanUp(self):
        for particle in self.particles:
            if particle is not None:
                particle.cleanUp(do_gc=False)
        gc.collect()
        
               
    def configureObservations(self, drifterSet="all", observationInterval=1, buoy_area='all'):
        """
        Configuring which drifters we will observe and how often we will observe them.
        
        Arguments:
            drifterSet: can contain the keyword "all" (default), which means that all drifters in the Observation file
                is considered. Otherwise it should be a set of drifter indices represented by a list.
            observationInterval: We choose to consider only every n'th observation.
        """
        if drifterSet != "all":
            self.observations.setDrifterSet(drifterSet)
        self.observations.setObservationInterval(observationInterval)
        self.driftersPerOceanModel = self.observations.get_num_drifters()
        self.observations.setBuoyReadingArea(buoy_area)
            
    def configureParticleInfos(self, extraCells):
        """
        Configuring which data to store from the ensemble.
        """
        self._particleInfoExtraCells = extraCells
        self._configureParticleInfos()
   
    def _configureParticleInfos(self):
        if self._particleInfoExtraCells is not None:
            for p in range(self.numParticles):
                self.particleInfos[p].setExtraCells(self._particleInfoExtraCells)
                
            
    def resample(self, newSampleIndices, reinitialization_variance):
        """
        Resampling the particles given by the newSampleIndicies input array.
        Here, the reinitialization_variance input is ignored, meaning that exact
        copies only are resampled.
        """
        obsTrueDrifter = self.observeTrueDrifters()
        positions = self.observeParticles()
        newOceanStates = [None]*self.getNumParticles()
        for i in range(self.getNumParticles()):
            index = newSampleIndices[i]
            
            # Download index's ocean state:
            eta0, hu0, hv0 = self.particles[index].download()
            eta1, hu1, hv1 = self.particles[index].downloadPrevTimestep()
            newOceanStates[i] = (eta0, hu0, hv0, eta1, hu1, hv1)

        # New loop for transferring the correct ocean states back up to the GPU:
        for i in range(self.getNumParticles()):
            self.particles[i].upload(newOceanStates[i][0],
                                     newOceanStates[i][1],
                                     newOceanStates[i][2],
                                     newOceanStates[i][3],
                                     newOceanStates[i][4],
                                     newOceanStates[i][5])
                      
    def step_truth(self):
        raise NotImplementedError("This function should not be used, as the truth is expected to file.")

    def step_particles(self):
        raise NotImplementedError("This class should only use the function stepToObservation, and not step_particles")
               
    def stepToObservation(self, observation_time, model_error_final_step=True, write_now=False, progress_info = False):
        """
        Advance the ensemble to the given observation time, and mimics CDKLM16.dataAssimilationStep function
        
        Arguments:
            observation_time: The end time for the simulation
            model_error_final_step: In IEWPF, the model error should not be applied to the final time step.
            write_now: Write result to NetCDF if an writer is active.
            
        """
        for p in range(self.getNumParticles()):
        
            # Only active particles are evolved
            if self.particlesActive[p]:
                self.particles[p].dataAssimilationStep(observation_time, model_error_final_step=model_error_final_step, write_now=write_now)
                
                if progress_info:
                    if p % 10 == 0:
                        print('Step done for particle ' + str(p))
            else:
                if progress_info:
                    print('skipping dead particle ' + str(p))
        self.t = observation_time
        
        
    def observeTrueDrifters(self, applyDrifterSet=True, ignoreBuoys=False):
        return self.observations.get_drifter_position(self.t, applyDrifterSet=applyDrifterSet, ignoreBuoys=ignoreBuoys)
    
    def getDrifterCells(self):
        drifter_positions = self.observations.get_drifter_position(self.t, applyDrifterSet=False)
        drifter_positions[:,0] = np.floor(drifter_positions[:,0]/self.getDx())
        drifter_positions[:,1] = np.floor(drifter_positions[:,1]/self.getDy())
        return drifter_positions.astype(np.int32)

    def getNumDrifters(self, applyDrifterSet=True):
        return self.observations.get_num_drifters(applyDrifterSet=applyDrifterSet)
        
    def observeTrueState(self):
        if not self.constant_depth:
            raise NotImplementedError("observations are not implemented for non-constant equilibrium depths")
        return self.observations.get_observation(self.t, self.mean_depth)
    
    
    def downloadTrueOceanState(self):
        eta, hu, hv, t = self.true_state_reader.getStateAtTime(self.t)
        return eta, hu, hv
    
    def getObservationVariance(self):
        return self.observation_cov[0,0]

    
    def registerStateSample(self, drifter_cells):
        assert(self.particleInfos is not None), 'particle info is None, and registerStateSample was called... This should not happend.'
        
        for p in range(self.getNumParticles()):
            # Only active particles are considered
            if self.particlesActive[p]:
                self.particleInfos[p].add_state_sample_from_sim(self.particles[p], drifter_cells)
                
                #if p == 0:
                #    self.particles[p].writeState()
            
    def dumpParticleInfosToFile(self, path_prefix):
        """
        File name of dump will be {path_prefix}{particle_id}_{dumpCounter}.bz2
        """
        assert(self.particleInfos is not None), 'particle info is None, and dumpParticleInfosToFile was called... This should not happend.'
        
        for p in range(self.getNumParticles()):
            filename = path_prefix + str(p).zfill(4) + "_" + str(self._particleInfoFileDumpCounter).zfill(2) + ".bz2"
            self.particleInfos[p].to_pickle(filename)
        
        self._particleInfoFileDumpCounter += 1
        
        # Reset particleInfos
        self._initializeParticleInfo()
        self._configureParticleInfos()
    
    def deactivateParticle(self, particle_id, msg=''):
        '''
        Deactivating the particle with the given particle id. 
        This particle will no longer be considered in the ensemble
        '''
        print('Deactivating particle ' + str(particle_id) + ' with the following message: ')
        print(msg)
        
        assert(self.particlesActive[particle_id]), 'Particle was already deactivated!'
    
        if self.cont_write_netcdf:
            self.particles[particle_id].writeState()
        self.particles[particle_id].cleanUp()
        
        self.particlesActive[particle_id] = False

    def deactivateDegeneratedParticles(self, dt_min, dt_max=0.0):
        '''
        Deactivating a particle in the ensemble 
        if the model time step exceeds dt_min or dt_max (if provided)
        '''
        for p in range(self.numParticles):
            if self.particlesActive[p]:
                dt = self.particles[p].dt 
                if dt < dt_min:
                    self.deactivateParticle(p, "dt < dt_min")
                if dt_max > 0.0 and dt > dt_max:
                    self.deactivateParticle(p, "dt > dt_max")
    
    def writeEnsembleToNetCDF(self):
        for p in range(self.getNumParticles()):
            # Only active particles are considered
            if self.particlesActive[p]:
                self.particles[p].writeState()
                